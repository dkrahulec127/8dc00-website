{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 1.4: Registration validation\n",
    "\n",
    "This notebook combines theory with exercises to support the understanding of validation in medical image registration. Implement all functions in the `code` folder of your cloned repository, and test it in this notebook after implementation by importing your functions to this notebook. Use available markdown sections to fill in your answers to questions as you proceed through the notebook.\n",
    "\n",
    "**Contents:** <br>\n",
    "\n",
    "1. [Evaluation and validation (concepts)](#eval_valid)<br>\n",
    "2. [Image similarity metrics](#img_sim_metrics)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='eval_valid'></div>\n",
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/read_ico.png\" width=\"42\" height=\"42\"></div> \n",
    "\n",
    "## 1. Evaluation and validation (concepts)\n",
    "\n",
    "The optimal fit for the fiducial markers does not automatically mean that the registration itself is optimal, especially if: the markers are far away from the object to be registered\n",
    "too few markers are used it is difficult to localize the markers.\n",
    "\n",
    "\n",
    "### Characteristics for evaluation of medical image analysis methods:\n",
    "Important characteristics to consider when evaluating medical image analysis methods:\n",
    "\n",
    "Accuracy = deviation of results from known ground truth.\n",
    "Precision, reproducibility, reliability = extent to which equal or similar input produces equal or similar results.\n",
    "Robustness characterizes the change of analysis quality if conditions deviate from assumptions made for analysis (e.g., when noise level increases or if object appearance deviates from prior assumptions).\n",
    "Efficiency = effort necessary to achieve an analysis result.\n",
    "\n",
    "\n",
    "\n",
    "ground truth = a conceptual term relative to the knowledge of the truth concerning a specific question (the “ideal expected result”)\n",
    "\n",
    "But the goal of medical imaging itself poses an inherent challenge… \n",
    "\n",
    "“In medical image analysis, the truth is difficult to come by, since the reason for producing images in the first place was to gather information about the human body that cannot be accessed otherwise.”\n",
    "\n",
    "\n",
    "So, how can we get a ground truth?\n",
    "\n",
    "A. Based on real data\n",
    "Artificial hardware (imaging) phantoms\n",
    "Cadaveric material\n",
    "\n",
    "Other imaging modality\n",
    "Other analysis method\n",
    "Expert annotations\n",
    "e.g., radiologists, pathologists\n",
    "(intra- & inter-observer variability?)\n",
    "\n",
    "\n",
    "So, how can we get a ground truth?\n",
    "\n",
    "B. Based on simulated data\n",
    "Software phantom\n",
    "E.g., XCAT phantom for PET validation, BrainWeb phantom, ultrasound phantom\n",
    "Mathematical simulations\n",
    "E.g., Shepp-logan phantom\n",
    "\n",
    "\n",
    "Example: evaluation of a segmentation task\n",
    "Which approach do we choose? \n",
    "\n",
    "Compare to ground truth:\n",
    "score = evaluate_segmentation(segmentation, ground_truth)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Validation\n",
    "13 Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 529\n",
    "13.1 Measures of Quality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 531\n",
    "13.1.1 Quality for a Delineation Task . . . . . . . . . . . . . . . . . . 532\n",
    "13.1.2 Considering Interaction in a Segmentation Task . . . . . 536\n",
    "13.1.3 Quality for a Detection Task . . . . . . . . . . . . . . . . . . . . 537\n",
    "13.1.4 Quality for a Registration Task . . . . . . . . . . . . . . . . . . 541\n",
    "13.2 The Ground Truth. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 542\n",
    "13.2.1 Ground Truth from Real Data . . . . . . . . . . . . . . . . . . . 543\n",
    "13.2.2 Ground Truth from Phantoms . . . . . . . . . . . . . . . . . . . 546\n",
    "13.3 Representativeness of Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . 552\n",
    "13.3.1 Separation Between Training and Test Data . . . . . . . . 552\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/question_ico.png\" width=\"42\" height=\"42\"></div>  \n",
    "\n",
    "### *Question 1.1:*\n",
    "\n",
    "How can we measure the quality of a registration task? Which consideration is important when selecting target points for which we measure registration performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:red\">Type your answer here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='img_sim_metrics'></div>\n",
    "\n",
    "## 2. Image similarity metrics\n",
    "\n",
    "The concepts of image-based similarity metrics (sum of square differences, cross-correlation and mutual information) were covered in the previous notebook on [Intensity-based registration](../reader/1.3_Registration_intensity-based-registration.ipynb).\n",
    "\n",
    "In this section, you will implement two such image similarity metrics: correlation and mutual information. The computation of the mutual information between two images relies on their joint histogram, so one of the exercises deals with the implementation of this intermediate step. In the project work section you will use the similarity metrics to find the optimal rotation transformation that aligns two images.\n",
    "\n",
    "Before you start, load your favorite test image in Python. You're going to use this image to test your implementation. Some of the examples below assume you work with images of type `uint8`, i.e. pixel intensities in the $[0, 255]$ range, but the provided functions are equipped to work with arbitrary image types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Normalized cross-correlation\n",
    "The normalized cross-correlation between two images $I$ and $J$ with pixels $i$ and respective\n",
    "mean intensities $\\overline{I}$ and $\\overline{J}$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "C=\\frac{\\sum_{i=1}^{n}(I(i)-\\overline{I})(J(i)-\\overline{J})}{\\sqrt{\\sum_{i=1}^{n}(I(i)-\\overline{I})^{2} \\sum_{j=1}^{n}(J(i)-\\overline{J})^{2}}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where n is the number of image pixels. If we reshape the 2D images to vectors (in Python this can be done with `numpy.reshape()`), the expression for the normalized cross-correlation can be rewritten using vector multiplication operators (which will also make it more clear how to implement it in Python):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "C=\\frac{(\\mathbf{u}-\\overline{I})^{\\top}(\\mathbf{v}-\\overline{J})}{\\sqrt{(\\mathbf{u}-\\overline{I})^{\\mathrm{T}}(\\mathbf{u}-\\overline{I})} \\sqrt{(\\mathbf{v}-\\overline{J})^{\\mathrm{T}}(\\mathbf{v}-\\overline{J})}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mathbf{u}$ and $\\mathbf{v}$ are vectors of the pixels intensities of the images $I$ and $J$, respectively:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "u=\\left[ \\begin{array}{c}{I(1)} \\\\ {I(2)} \\\\ {\\vdots} \\\\ {I(n)}\\end{array}\\right], v=\\left[ \\begin{array}{c}{J(1)} \\\\ {J(2)} \\\\ {\\vdots} \\\\ {J(n)}\\end{array}\\right]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/todo_ico.png\" width=\"42\" height=\"42\"></div>  \n",
    "\n",
    "### *Exercise 2.1.1:*\n",
    "\n",
    "The provided function `correlation()` in `SECTION 3` of the `registration.py` module contains a template for implementing the normalized cross-correlation metric. Most of the functionality such as parameter checking and pre-processing of the images is already implemented. The only piece of code that is missing is the computation of the normalized cross-correlation using the equation above.\n",
    "\n",
    "Implement the missing functionality in the `correlation()` function. Note that the mean intensity is already subtracted from the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/todo_ico.png\" width=\"42\" height=\"42\"></div>  \n",
    "\n",
    "### *Exercise 2.1.2:*\n",
    "\n",
    "Test your implementation using the template `correlation_test()` script provided in `SECTION 3` of the `registration_tests.py` module. For example, you can make sure that `correlation(I,I)`, i.e. the normalized cross-correlation of any image with itself, returns 1. Use some other properties of normalized cross-correlation in order to further test your implementation. (**Tip**: How does a linear transformation of the intensities of the images affect the normalized cross-correlation coefficient?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "from registration_tests import correlation_test\n",
    "\n",
    "correlation_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/question_ico.png\" width=\"42\" height=\"42\"></div>  \n",
    "\n",
    "### *Question 2.1.1:*\n",
    "\n",
    "Under which assumptions is the normalized cross-correlation the optimal similarity metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:red\">Type your answer here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Joint histogram\n",
    "\n",
    "The `joint_histogram()` function in `SECTION 3` of the `registration.py` module contains an almost complete implementation of computation of the joint histogram of two images. We use the joint histogram as an estimate of the joint probability mass function (PMF) of two images. This function informs us of the probability that two intensities co-occur (appear together) at the same location in the two images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/todo_ico.png\" width=\"42\" height=\"42\"></div>  \n",
    "\n",
    "### *Exercise 2.2.1:*\n",
    "\n",
    "Go over the implementation and make sure you understand the functionality of all the steps in the code. Implement the last missing step in the computation of the joint histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/question_ico.png\" width=\"42\" height=\"42\"></div>  \n",
    "\n",
    "### *Question 2.2.1:*\n",
    "\n",
    "One of the parameters of the function is num bins, which defines the number of bins of the joint histogram. The default value for this parameter in this implementation is chosen to be 16. We mostly work with 8-bit images that have 256 possible values for the pixel intensities, which means that num bins can go as high as 256. However, there is a trade-off between choosing num bins too low or too high. What is this trade-off?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:red\">Type your answer here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Mutual Information\n",
    "\n",
    "Given the joint PMF of the two images $p_{I, J}$ and the two marginal PMF's (the PMF's of the individual images) $p_{I}$ and $p_{I}$, the mutual information can be computed according to the following equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "M I(I, J)=\\sum_{i=1}^{n} \\sum_{j=1}^{n} p_{I, J}(i, j) \\log \\frac{p_{I, J}(i, j)}{p_{I}(i) p_{J}(j)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the joint histogram is an estimate of the joint PMF. Thus, in the previous equation, we can \"plug in\" the joint histogram for $p_{I, J}$, and analogously, the marginal histograms (the histograms of the individual images) for $p_{I}$ and $p_{J}$. The two sum operators go over all bins in the joint histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/todo_ico.png\" width=\"42\" height=\"42\"></div>  \n",
    "\n",
    "### *Exercise 2.3.1:*\n",
    "\n",
    "A template for implementation of mutual information given a joint histogram of two images is given in the Python function `mutual_information()` in `SECTION 3` of the `registration.py` module. As before, the file already contains all the pre-processing steps but the actual computation of the mutual information is missing. The only missing piece of code in the template file is implementation of the above formula for mutual information. Implement the missing functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/todo_ico.png\" width=\"42\" height=\"42\"></div>  \n",
    "\n",
    "### *Exercise 2.3.2:*\n",
    "\n",
    "Use some of the properties of mutual information to test your implementation. Write these tests in the provided `mutual_information_test()` script in `SECTION 3` of the `registration_tests.py` module. (**Tip**: What would be the mutual information of two random noise images? You can generate random noise `uint8` images with `np.random.randint(255, size=(512, 512))`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "from registration_tests import mutual_information_test\n",
    "\n",
    "mutual_information_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/todo_ico.png\" width=\"42\" height=\"42\"></div>  \n",
    "\n",
    "### *Exercise 2.3.3:*\n",
    "\n",
    "An alternative formula for mutual information is:\n",
    "\n",
    "$$\n",
    "MI(I,J)=H(I)+H(J)-H(I, J)\n",
    "$$\n",
    "\n",
    "In the previous equation, $H(I)$ and $H(J)$ is the entropy of the images $I$ and $J$ and $H(I,J)$ is their joint entropy. \n",
    "\n",
    "Find out the equation for the entropy and implement mutual information, using this formula, in the `mutual_information_e()` function in `SECTION 3` of the `registration.py` module. Test your implementation with the provided `mutual_information_e_test()` script. Make sure that both implementations output equal values (very small differences are possible due to rounding errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"../code\")\n",
    "from registration_tests import mutual_information_e_test\n",
    "\n",
    "mutual_information_e_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/question_ico.png\" width=\"42\" height=\"42\"></div>  \n",
    "\n",
    "### *Question 2.3.1:*\n",
    "\n",
    "When is mutual information preferable over sum of squared errors and normalized cross-correlation as an image similarity metric? Motivate your answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:red\">Type your answer here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:right;margin:-5px 5px\"><img src=\"../reader/assets/question_ico.png\" width=\"42\" height=\"42\"></div>  \n",
    "\n",
    "### *Question 2.3.2:*\n",
    "\n",
    "The output of `mutual_information()` is described as \"*mutual information in nat units*\". What change in the code would you have to make to output the mutual information in bits? Does it make a difference which units you output when you use the mutual information metric in practice (for example, to perform image registration)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style=\"color:red\">Type your answer here</font>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "7cf3cfb4d2a53586223bf4603cd7f9e645cf44a77dbcec96182c9a81e54296ad"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
